---
layout: post
title: Notes of PDSC&#58 Chapter 7
tags: [python, numpy, notes]
---

As a general rule, the smaller the data structure, the faster your computation.

Object-oriented languages can be especially problematic, as there might be many unused methods attached to your large data structures that need to be moved around with each loop iteration.

Overall guidance of computing optimization:

1. Highlight any and all loops, especially nested loops: the higher the level of nesting, the slower they often are.
2. Locate slow mathematical operations such as square roots, trigonometric functions, and so on, or anything that is not an addition or subtraction.
3. Shrink the size of key data structures.
4. Determine the precision ( oat, double, int, uint8, and so on) of often used variables.
5. Avoid unnecessary calculations when possible.
6. Attempt to simplify mathematical equations.

Additions and subtractions are faster than multiplications that are usually faster than division operations.

Unfortunately, the square root calculation itself is quite slow compared to basic multiplication, division, addition, subtraction, and logical comparisons. Even then, multiplications and divisions are usually significantly slower than your basic addition, subtraction, and logical comparisons.

In fact, often, an 8-bit integer will do, and sometimes an unsigned integer, which is incapable of expressing a negative value, is even better.

`xrange` only allocates memory for the `xrange` object and provides numbers on demand and as required. Also, `xrange()` is implemented in pure C.

Use `python -m cProfile` to check the time consumption of each method in a Python script.

The output from cProfile consists of plain text organized into five columns as follows:

1. `ncalls`: This shows you how many times the function is called
2. `tottime`: This shows you the time spent on the function, excluding the time spent on calling other functions
3. `percall`: This shows you the total time, divided by `ncalls`
4. `cumtime`: This shows you the time spent on the function, including calls to other functions
5. `percall`: This shows you the `cumtime` value divided by `tottime`

One of the keys to NumPy's performance is that each element of the array must be of the same data type.

  1. This homogeneity allows for very efficient memory packing and locality of reference.
  2. This is in stark contrast to Python lists, which can contain objects of varied data types and occupy different amounts of memory.
